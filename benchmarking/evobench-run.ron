// More docs may be available in the evobench source code, start with
// `RunConfig` in `evobench-evaluator/src/run/config.rs`

RunConfig(
    queues: (
        // run_queues_basedir: Some("other/path/than/home/.evobench-run/queues/"),

        // List of queues each job goes through in order--subdirectory
        // name and queue configuration
        pipeline: [
            ("immediately1", Immediately),
            ("immediately2", Immediately),
            // "local naive time" is a time without date that matches
            // every day, in the local time zone. Jobs in such a queue
            // are run in the given time window, only. When the time
            // window is entered, the `stop_start` command is run with
            // an additional `stop` argument, when the window ends or
            // all jobs are finished, it is run with `start`.
            ("day", LocalNaiveTimeWindow(
                stop_start: Some([
                    "echo",
                    "running during the day:",
                ]),
                // When `repeatedly` is false, the job is run only
                // once then moved to the next queue. When `true`, the
                // job is run until its `count` reaches 0 or the time
                // window runs out.
                repeatedly: false,
                // If true, unfinished jobs in this queue are moved to
                // the next queue when the time window ends.
                move_when_time_window_ends: true,
                from: "17:00:00",
                to: "18:00:00",
            )),
            ("night", LocalNaiveTimeWindow(
                stop_start: Some([
                    "echo",
                    "running in the night:",
                ]),
                repeatedly: true,
                move_when_time_window_ends: true,
                from: "2:00",
                to: "7:00",
            )),
            // `GraveYard` queues do not run their jobs, meaning jobs
            // that are moved here stay forever; this is meant as a
            // debugging/verification tool (omitting this last queue
            // would get them deleted instead)
            ("grave_yard", GraveYard),
        ],

        // Where jobs go when they run out of error_budget (`None`
        // would get them deleted instead)
        erroneous_jobs_queue: Some(
            ("erroneous_jobs", GraveYard)
        ),
    ),

    working_directory_pool: (
        // base_dir: Some("other/path/than/home/.evobench-run/working_directory_pool/"),

        // Smaller: less disk space use for build dirs, but less
        // chance to re-use a build with the same commit id without
        // having to rebuild
        capacity: 6,
    ),

    remote_repository: (
        // For server use:
        // url: "https://github.com/GenSpectrum/LAPIS-SILO/",

        // For benchmarking local developments, give the path to your local working directory:
        url: "~/LAPIS-SILO",

        // For the `poll` subcommand:
        remote_branch_names: [
            "main"
        ]
    ),

    // A list of *all* environment variables your benchmarking process
    // can take, with a boolean that says whether they are also
    // *required* (do *not* list the environment variables which the
    // evobench daemon passes anyway (i.e. are not custom):
    // "COMMIT_ID", "EVOBENCH_LOG", "BENCH_OUTPUT_LOG")
    custom_parameters_required: {
        "SORTED": true,
        "RANDOMIZED": true,
        "BENCHMARK_DATASET_NAME": true,
    },

    // Each `CustomParameters` group is used for a separate benchmark
    // run for each commit it.
    custom_parameters_set: CustomParametersSet([
        CustomParameters({
            "SORTED": "1",
            "RANDOMIZED": "1",
            "BENCHMARK_DATASET_NAME": "full",
        }),
        CustomParameters({
            "SORTED": "0",
            "RANDOMIZED": "1",
            "BENCHMARK_DATASET_NAME": "full",
        }),
    ]),

    // Each job receives a copy of these settings
    benchmarking_job_settings: BenchmarkingJobSettings(
        // How many times to run the same benchmarking job (higher:
        // better statistics, at higher cost); default: 5
        count: Some(5),
        // How many times the job can fail before it is moved to the
        // `erroneous_jobs_queue` (or dropped if that is `None`);
        // default: 3
        error_budget: Some(1)
    ),

    // What command to run on the target project to execute a
    // benchmarking run; the env variables configured in
    // CustomParameters are set when running this command.
    benchmarking_command: BenchmarkingCommand(
        // Relative path to the subdirectory (provide "." for the top
        // level of the working directory) where to run the command
        subdir: "benchmarking",
        command: "make",
        arguments: ["bench"],
    ),

    /// The base of the directory hierarchy where the output files
    /// should be placed
    output_base_dir: "~/silo-benchmark-outputs",
)
